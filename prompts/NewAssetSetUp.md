<Instructions>
I am providing you with certain files from a Github repo. They are the code for a Dagster based data pipeline for ingesting data from the Socrata API for analysis. Analyze the files and understand how the entire repo works. Then, provide a detailed explanation of the repo. Start off with general, easy understand explanation of what the repo does and how it is organized. Then, explain the repo, starting with the pipeline/definitions.py file, and then outward from there. Explain how the definitions.py file is the entry point for your data project. where you define what assets and code you want to use with Dagster, in an easy-to-understand way. Then, provide a hierarchal explanation of the various sections of the code and their files. Use the example_mta_operations_statement asset as an example in explaining how the code works. Explain how it is made as an @asset in mta_assets.py, and how the code works with using the socrata dagster configurable resource, and how it uses a polars based data processing function for data cleaning, be sure to explain every single part of both assets processing functions polars code. Make some critical observations about how the polars data processing function code works in general and then make a critical observation into how this polars code uses with_columns and format= instead of with_column or fmt=, this is very important to note for all you polars coding. Then, explain it how it works when the asset is materialized from the Dagster UI. Explain the full flow of how Dagster spins up a run, makes the API call with socrata, ingests JSON, we read it into a polars dataframe, we run our polars processing function and what this polars code is changing, the function returns a final polars dataframe, and finally how the single file polars parquet io manager works for storing the io_manager as a parquet file. Be sure to explain how the Dagster metadata tags work for the asset, and make note of how the code is structured at the end of the code to return the final dataframe along with the Dagster Output for metadata as seperate parts of the code. Explain how the definitions.py imports LAKE_PATH from constants.py and how that works for the naming convention of storing the files locally with the single file polars parquet io manager. Then, explain the three DBT files provided and how they set up the DBT project, and how we will be updated the sources.yml with our new assets we create now. Explain how each sections files work and how they work together to make the repo work in a clear, detailed, but concise way, that provides explanation of the code but doesn't go overly into the weeds.

Then, prepare yourself for the final step of your response. Over the course of our conversation, we are going to use this code mtadata repo as a base for building our own Dagster based data pipeline for ingesting data from the Socrata API.  After you next response, I will be providing you all of the input information necessary for our next asset that will be needed to create a new Dagster @asset that uses the socrata_resource and the single file polars parquet io manager. Here are some of the details. I want to make a simple version first, that downloads the entire dataset but does not perform any data processing on it. This simple asset should print its columns and a sample of three rows. We want to maintain the existing format of the defintions.py, datasets.py, constants.py, and duckdb_warehouse.py as much as possible. 

<Summary of Instructions>
To summarize your instructions, you will be taking a deep dive into understanding everything about the files I have sent you, so that you will know how to use them as a guide, along with your general knowledge, in customizing the repo for our own custom data pipeline. In my next response, I will be providing you with the simple input information of a brand new socrata asset we will be downloading from the NYC data portal, which we will use to make a quick API call to download a sample and inspect the data. After confirming that, we will be adding a processing function. So for now, provide the first part of your response now as you deeply analyze the code and prepare an action plan to customize the code. 